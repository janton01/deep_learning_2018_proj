{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import imgpreprocess\n",
    "import torchvision.models as md\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv3x3(in_planes, out_planes):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1, padding=1,bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.elu = nn.ELU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.elu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.elu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        self.inplanes = 1\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.elu = nn.ELU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 32)\n",
    "        self.layer2 = self._make_layer(block, 64)\n",
    "        self.layer3 = self._make_layer(block, 128)\n",
    "        self.layer4 = self._make_layer(block, 256)\n",
    "        self.avgpool = nn.AvgPool2d(5, stride=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes):\n",
    "        downsample = None\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(self.inplanes, planes, kernel_size=5, stride=2, padding=0, bias=False))\n",
    "        layers.append(nn.ELU())\n",
    "        self.inplanes = planes * block.expansion\n",
    "        layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x / (torch.sqrt(torch.sum(x**2, 1)).view(-1, 1))\n",
    "        x = x * 10\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    model = ResNet(BasicBlock, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rnnmodel(nn.Module):\n",
    "\n",
    "    def __init__(self, charcount):\n",
    "        super(rnnmodel, self).__init__()\n",
    "        self.charcount = charcount\n",
    "        self.embed_size = 100\n",
    "        self.hidden_size = 256\n",
    "        self.embedding = nn.Embedding(charcount, self.embed_size)\n",
    "        self.rnn = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, num_layers=2, dropout=0.7, batch_first=True)\n",
    "        # self.scoring = nn.Linear(self.hidden_size, charcount)\n",
    "\n",
    "\n",
    "    def forward(self, x, length):\n",
    "        batch_size = x.size(0)\n",
    "        embed = self.embedding(x)\n",
    "        hidden = None\n",
    "        x_packed = rnn.pack_padded_sequence(embed, length,batch_first=True)\n",
    "        output_lstm, hidden = self.rnn(x_packed)\n",
    "        output_lstm,_ = rnn.pad_packed_sequence(output_lstm,batch_first=True, total_length=210)\n",
    "        # output_lstm = output_lstm.view(-1, self.hidden_size)\n",
    "        # output_lstm = self.scoring(output_lstm)\n",
    "        return output_lstm.contiguous().view(batch_size, -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class finalmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(finalmodel, self).__init__()\n",
    "        self.cnnmodel = md.resnet18(pretrained=True)\n",
    "        self.rnnmodel = rnnmodel(1957)\n",
    "        self.linear1 = nn.Linear(1000,4096)\n",
    "        self.linear2 = nn.Linear(4096,2048)\n",
    "        self.linear3 = nn.Linear(2048,2)\n",
    "        self.prepro = nn.Conv2d(1 ,3,kernel_size=64, stride=1, padding=1, bias=False)\n",
    "#         for parm in self.cnnmodel.parameters():\n",
    "#             parm.requires_grad = False\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "    def forward(self, input_pic, input_rep, length):\n",
    "#         output_rep = self.rnnmodel(input_rep,length)\n",
    "        input_pic = input_pic.unsqueeze(1)\n",
    "        input_pic = self.prepro(input_pic)\n",
    "        output_pic = self.cnnmodel(input_pic)\n",
    "\n",
    "#         input_cat = torch.cat((output_pic, output_rep), dim=-1)\n",
    "#         input_cat = self.linear1(input_cat)\n",
    "#         input_cat = F.relu(input_cat)\n",
    "#         input_cat = self.linear2(input_cat)\n",
    "        out = self.linear1(output_pic)\n",
    "        out = F.leaky_relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.leaky_relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/picture_data.npy')\n",
    "report = np.load('data/report.npy')\n",
    "labels = np.load('data/labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = 0.1\n",
    "epoch=4\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_whole = np.arange(data.shape[2])\n",
    "np.random.shuffle(index_whole)\n",
    "\n",
    "val_data = data[:, :,index_whole[:int(data.shape[2]*0.1)]]\n",
    "val_report = report[index_whole[:int(data.shape[2]*0.1)]]\n",
    "val_labels = torch.Tensor(labels[index_whole[:int(data.shape[2]*0.1)]])\n",
    "distribution = val_labels.sum() / val_labels.shape[0]\n",
    "train_data = data[:, :, index_whole[int(data.shape[2]*0.1):]]\n",
    "train_report = report[index_whole[int(data.shape[2]*0.1):]]\n",
    "train_labels = torch.Tensor(labels[index_whole[int(data.shape[2]*0.1):]])\n",
    "print(distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = finalmodel()\n",
    "criterial = nn.CrossEntropyLoss(weight=torch.Tensor([1/77, 1/23]))\n",
    "# criterial = nn.MSELoss()\n",
    "SGDOptimizer = torch.optim.Adam(model.parameters())\n",
    "train_index = torch.arange((data.shape[2] - int(data.shape[2]*0.1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = Data.TensorDataset(train_index, train_labels)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "val_index = torch.arange(int(data.shape[2]*0.1))\n",
    "val_dataset = Data.TensorDataset(val_index, val_labels)\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size = batch_size*2,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_num 0,loss 0.8770, acc 0.2500\n",
      "batch_num 30,loss 0.5301, acc 0.7812\n",
      "batch_num 60,loss 0.4621, acc 0.8438\n",
      "batch_num 90,loss 0.6165, acc 0.6875\n",
      "batch_num 120,loss 0.4728, acc 0.7812\n",
      "batch_num 150,loss 0.5895, acc 0.7500\n",
      "batch_num 180,loss 0.4185, acc 0.8750\n",
      "batch_num 210,loss 0.4685, acc 0.8438\n",
      "batch_num 240,loss 0.5262, acc 0.7812\n",
      "batch_num 270,loss 0.6620, acc 0.6562\n",
      "batch_num 300,loss 0.4463, acc 0.8438\n",
      "batch_num 330,loss 0.4934, acc 0.7188\n",
      "batch_num 360,loss 0.3564, acc 0.9062\n",
      "batch_num 390,loss 0.5088, acc 0.8125\n",
      "batch_num 420,loss 0.5991, acc 0.7500\n",
      "batch_num 450,loss 0.7676, acc 0.6250\n",
      "batch_num 480,loss 0.4680, acc 0.7812\n",
      "batch_num 510,loss 0.6815, acc 0.6562\n",
      "batch_num 540,loss 0.3269, acc 0.8750\n",
      "batch_num 570,loss 0.4907, acc 0.7500\n",
      "batch_num 600,loss 0.6806, acc 0.5938\n",
      "batch_num 630,loss 0.5612, acc 0.7812\n",
      "batch_num 660,loss 0.5335, acc 0.7812\n",
      "batch_num 690,loss 0.6104, acc 0.7188\n",
      "batch_num 720,loss 0.6204, acc 0.6562\n",
      "batch_num 750,loss 0.6376, acc 0.6562\n",
      "train_loss 0.5697\n",
      "val_loss 0.5489, val_acc: 0.7740\n",
      "batch_num 0,loss 0.4214, acc 0.8750\n",
      "batch_num 30,loss 0.5743, acc 0.6875\n",
      "batch_num 60,loss 0.4310, acc 0.8750\n",
      "batch_num 90,loss 0.5915, acc 0.6875\n",
      "batch_num 120,loss 0.5134, acc 0.8125\n",
      "batch_num 150,loss 0.6105, acc 0.6562\n",
      "batch_num 180,loss 0.6987, acc 0.6562\n",
      "batch_num 210,loss 0.4630, acc 0.8125\n",
      "batch_num 240,loss 0.5726, acc 0.6875\n",
      "batch_num 270,loss 0.4848, acc 0.7812\n",
      "batch_num 300,loss 0.7114, acc 0.6562\n",
      "batch_num 330,loss 0.6246, acc 0.6250\n",
      "batch_num 360,loss 0.5615, acc 0.7188\n",
      "batch_num 390,loss 0.3541, acc 0.8750\n",
      "batch_num 420,loss 0.4687, acc 0.8125\n",
      "batch_num 450,loss 0.5513, acc 0.6875\n",
      "batch_num 480,loss 0.4283, acc 0.7500\n",
      "batch_num 510,loss 0.4671, acc 0.8125\n",
      "batch_num 540,loss 0.4588, acc 0.7188\n",
      "batch_num 570,loss 0.4341, acc 0.8125\n",
      "batch_num 600,loss 0.5218, acc 0.7500\n",
      "batch_num 630,loss 0.5082, acc 0.7500\n",
      "batch_num 660,loss 0.5191, acc 0.7812\n",
      "batch_num 690,loss 0.6331, acc 0.8438\n",
      "batch_num 720,loss 0.7701, acc 0.6562\n",
      "batch_num 750,loss 0.4999, acc 0.8125\n",
      "train_loss 0.5304\n",
      "val_loss 0.5881, val_acc: 0.7744\n",
      "batch_num 0,loss 0.5900, acc 0.7188\n",
      "batch_num 30,loss 0.5062, acc 0.8125\n",
      "batch_num 60,loss 0.6460, acc 0.6875\n",
      "batch_num 90,loss 0.7693, acc 0.6562\n",
      "batch_num 120,loss 0.6048, acc 0.6875\n",
      "batch_num 150,loss 0.4086, acc 0.8438\n",
      "batch_num 180,loss 0.4386, acc 0.8125\n",
      "batch_num 210,loss 0.5602, acc 0.7188\n",
      "batch_num 240,loss 0.5659, acc 0.6875\n",
      "batch_num 270,loss 0.6690, acc 0.6562\n",
      "batch_num 300,loss 0.4631, acc 0.8125\n",
      "batch_num 330,loss 0.4154, acc 0.9062\n",
      "batch_num 360,loss 0.5149, acc 0.7812\n",
      "batch_num 390,loss 0.3568, acc 0.8125\n",
      "batch_num 420,loss 0.3927, acc 0.8438\n",
      "batch_num 450,loss 0.6489, acc 0.8125\n",
      "batch_num 480,loss 0.3286, acc 0.9062\n",
      "batch_num 510,loss 0.5777, acc 0.6875\n",
      "batch_num 540,loss 0.6424, acc 0.6250\n",
      "batch_num 570,loss 0.4910, acc 0.7500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(epoch):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_num,(idx, label) in enumerate(loader):\n",
    "        train_acc=0\n",
    "        idx = idx.long()\n",
    "        SGDOptimizer.zero_grad()\n",
    "        img_imput = train_data[:,:,idx].transpose(2, 0, 1)\n",
    "        rep_input = train_report[idx]\n",
    "        max_len = 0\n",
    "        length = torch.zeros(idx.shape[0]).long()\n",
    "        label = torch.Tensor(label)\n",
    "        for i in range(idx.shape[0]):\n",
    "            length[i] = rep_input[i].shape[0]\n",
    "            if rep_input[i].shape[0] > max_len:\n",
    "                max_len = rep_input[i].shape[0]\n",
    "        report_batch = torch.zeros((idx.shape[0],max_len)).long()\n",
    "        for i in range(idx.shape[0]):\n",
    "            report_batch[i, :length[i]] = torch.Tensor(rep_input[i]).long()\n",
    "        _, sortid = torch.sort(length, dim=0, descending=True)\n",
    "        length = length.index_select(0,sortid).cuda()\n",
    "        report_batch = report_batch.index_select(0,sortid)\n",
    "        label = label.index_select(0,sortid).cuda().long()      \n",
    "        img_imput = torch.Tensor(img_imput)\n",
    "        img_imput = img_imput.index_select(0,sortid).cuda()\n",
    "        report_batch = report_batch.cuda()\n",
    "        length = length.cuda()\n",
    "        logits = model.forward(img_imput, report_batch, length)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        t = (pred.cpu().numpy() == label.cpu().numpy())\n",
    "        train_acc = np.sum(t)/pred.shape[0]\n",
    "        ###for mse\n",
    "#         label_tmp = torch.zeros((idx.shape[0],2))\n",
    "#         for i in range(idx.shape[0]):\n",
    "#             label_tmp[i,label[i]]=1\n",
    "#         label = label_tmp.cuda()\n",
    "        ###\n",
    "        loss = criterial(logits, label)\n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        SGDOptimizer.step()\n",
    "        if batch_num%30 == 0:\n",
    "            print(\"batch_num {0},loss {1:.4f}, acc {2:.4f}\".format(batch_num, loss.item(), train_acc))\n",
    "    epoch_loss = epoch_loss / (batch_num + 1)\n",
    "    print(\"train_loss {0:.4f}\".format(epoch_loss))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss=0\n",
    "        val_acc = 0\n",
    "        for batch_num, (idx, label) in enumerate(val_loader):\n",
    "            idx = idx.long()\n",
    "            img_imput = train_data[:, :, idx].transpose(2, 0, 1)\n",
    "            rep_input = val_report[idx]\n",
    "            max_len = 0\n",
    "            length = torch.zeros(idx.shape[0]).long()\n",
    "            sortid=sortid.cuda()\n",
    "            label = torch.Tensor(label)\n",
    "            for i in range(idx.shape[0]):\n",
    "                length[i] = rep_input[i].shape[0]\n",
    "                if rep_input[i].shape[0] > max_len:\n",
    "                    max_len = rep_input[i].shape[0]\n",
    "            report_batch = torch.zeros((idx.shape[0], max_len)).long()\n",
    "            for i in range(idx.shape[0]):\n",
    "                report_batch[i, :length[i]] = torch.Tensor(rep_input[i]).long()\n",
    "            _, sortid = torch.sort(length, dim=0, descending=True)\n",
    "            report_batch = report_batch.index_select(0, sortid)\n",
    "            length = length.index_select(0,sortid).cuda()\n",
    "            label = label.index_select(0, sortid).cuda().long()\n",
    "            img_imput = torch.Tensor(img_imput)\n",
    "            img_imput = img_imput.index_select(0, sortid).cuda()\n",
    "            report_batch = report_batch.cuda()\n",
    "            length = length.cuda()\n",
    "            logits = model.forward(img_imput, report_batch, length)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            t = (pred.cpu().numpy() == label.cpu().numpy())\n",
    "            val_acc += np.sum(t)/pred.shape[0]\n",
    "            ###for mse\n",
    "#             label_tmp = torch.zeros((idx.shape[0],2))\n",
    "#             for i in range(idx.shape[0]):\n",
    "#                 label_tmp[i,label[i]]=1\n",
    "#             label = label_tmp.cuda()\n",
    "            ###\n",
    "            loss = criterial(logits, label)\n",
    "            val_loss+=loss\n",
    "        val_loss = val_loss / (batch_num+1)\n",
    "        val_acc = val_acc / (batch_num+1)\n",
    "        print(\"val_loss {0:.4f}, val_acc: {1:.4f}\".format(val_loss, val_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
